---
title : "Text processing"
date : today
css: styles.css  # Link to your custom CSS file
execute: 
  echo: false
  warning: false
format: 
    revealjs:
        highlight-style: breeze
        theme: simple
        pdf-separate-fragments: false
        self-contained: true
bibliography : references.bib
editor_options: 
  chunk_output_type: console
---

## Manipulating text

## Dictionnaries and pattern detection

- "Easiest" method to work with text
- Measurement approach : if a word is in the text, then the text is about this topic

## Limit of dictionnaries

## Converting text to numbers

- Text as data consists in transforming text into numbers
- Different ways to do this
- Start with bag of words representation

## Document feature matrix {.smaller}

```{r}

library(tidyverse)
library(tidytext)
library(here)


uk_manifesto <- read_csv(here("data", "gbr_manifesto_corpus.csv")) |> 
    filter(partyname %in% c("Conservative Party", "Labour Party")) |> 
    # Shorten names
    mutate(partyname = case_when(
        partyname == "Conservative Party" ~ "Conservative",
        partyname == "Labour Party" ~ "Labour"
    )) 

set.seed(123)

uk_manifesto |> 
    slice_sample(n = 10)  |> 
    # Keep only first 5 words
    unnest_tokens(word, text) |> 
    count(text_id,  partyname, word) |> 
    pivot_wider(names_from = word, values_from = n, values_fill = 0) |> 
    select(text_id, partyname, we, understand, these, feelings, of, our, country) |> 
    kableExtra::kable()

```

## Sparse matrix : a lot of zeros {.smaller}

```{r}
# Zipf's law

uk_manifesto |> 
    unnest_tokens(word, text) |> 
    count(word, sort = TRUE) |> 
    mutate(rank = row_number()) |> 
    ggplot(aes(x = rank, y = n)) +
    geom_point() +
    scale_x_log10("Rank") +
    scale_y_log10("N") +
    theme_minimal() + 
    # Add some labels with texts
    geom_text(aes(label = word), nudge_x = 0.5, nudge_y = 0.5, check_overlap = TRUE)


```





## Tokenization {.smaller}

```{r}
#| echo: true




set.seed(1)
sentence_demo <- uk_manifesto |> 
    slice_sample(n = 1) 

sentence_demo |> pull(text)


```


## Creating DTMs

- Creation of corpus : getting texts
- Tokenization
- Standardization
- Filtering : stopwords, counts, only nound
- Computation
- Weighting




