---
title: "Collecting online data"
subtitle: "Introduction on webscraping"
author: "Malo Jan"
date: today
format: 
  revealjs:
    slide-number: c/t
    footer: "Collecting online data"
    theme: simple
    echo: true
    incremental: false

---

## What is web scraping? {.smaller}

<br>

::: {.fragment fragment-index=1}

> Web scraping is a data collection technique on the web that involves extracting data from a web page.

:::

::: {.fragment fragment-index=2}

- We are all manual web scrapers: copying/pasting/downloading data from the web daily.
- But we can automate all of this: machines are faster and more extensive than we are.
:::

## Use cases {.smaller}

- Collecting social media data
- Collecting press releases from an organization, speeches from actors
- Extracting data from wikipedia pages
- Automatically download hundreds of pdfs from a website
- Collect meta data from a website

# How the web is written

## How the web is written {.smaller}

- Web scraping involves a minimum understanding of how the web is written: what is a web page?
    - Code: interpreted by a browser (ex: Chrome, Mozilla)

- The code of a web page can be written in:
    - HTML (**Hypertext markup language**): structure and content
    - CSS: style (ex: font, color)
    - Javascript: functionalities, dynamic content, search, drop-down menus etc.

- Exemple from the press release of the [UN Secretary General](https://press.un.org/en/content/secretary-general/press-release)

## HTML {.smaller}

- HTML is a markup language
- The content of the web is written in tags, which can have attributes
- Most common tags in html
    - div
    - p
    - h1, h2, h3

- Web scraping consists in extracting the content of the html source code to get certain information
- CTRL + U /Selector Gadget

# Web scraping ethics

## Ethics on data access {.smaller}

- Web scraping is about collecting data not intended for you
    - May be illegal but also exceptions for [research purposes]((https://www.ouvrirlascience.fr/la-fouille-de-textes-et-de-donnees-a-des-fins-de-recherche-une-pratique-confirmee-et-desormais-operationnelle-en-droit-francais/))
    - Access to private data, overload servers
    - Websites can block you/track you

- Good practices :
    - API first
    - Check permissions (robot.txt)
    - Slow down scraping

## Ethics on data use {.smaller}

:::: {.columns}
::: {.column width="60%"}

- Web scraping can be used to collect personal and sensitive data
- Eg. Old twitter API: possibility to download all tweets of a user in 2 lines of code
- Data protection laws (GDPR) apply to web scraping
- Need to think about the use of the data

:::

::: {.column width="40%"}

![](images/01_scrap.png){.absolute top=100 right=10 width="400" height="400"}
:::
::::

# Web scraping challenges

## Complex and dynamic pages {.smaller}

:::: {.columns}
::: {.column width="60%"}

- Web pages are sometimes complex and dynamic (javascript)
- More complex scraping strategies are needed
- Selenium: allows to simulate clicks on a browser from a script
- Web pages are also changed, updated: your program can work one day and not the next, good practice to download the hmtl pages on your computer

:::

::: {.column width="40%"}
![](images/01_scrap_2.jpg){.absolute top=100 right=0 width="300" height="300"}
:::

::::

## Dirty data {.smaller}

- Web scraping is often just the first step and can involve a lot of cleaning, text manipulation, parsing to get structured information
- Requires additional skills and tools like *regular expressions* (regex) : see the package [stringr](https://stringr.tidyverse.org/) in R





